매니폴드 러닝



1. 밀도가 낮은 고차원 공간안에 이들을 아우르는 저차원 매니폴드가 존재한다(dominant features)는 가정하에, 이 매니폴드를 학습하여 차원 축소를 이루는 방법론.

2.차원 축소를 통해 크게 네가지 성취 가능

	1) 데이터 압축
	2) 데이터 시각화
	3) 차원의 저주 해소(고차원 공간으로 갈수록 모델 추정에 필요한 데이터의 수가 기하급수적으로 증가함에따라 학습이 이루어지지 않는 현상을 차원 축소로 극복)
	4) 가장 중요한 특징 발견


3. 200*200 RGB 공간내에는 손글씨 데이터도 있고, 얼굴 데이터도 있고, 스케치 데이터도 있음. 
GAN 같은 모델에서는 학습데이터를 통해(도메인을 한정함에 따라) 해당 데이터와 유사한 매니폴드를 학습할 수 있고, 
거기서 샘플링한 데이터로 가짜 데이터를 생성할 수 있는것임

4. manifold가 entangle되어 있다: 데이터 공간 내에 복잡하게 인코드 되어 있다,  표현형이 복잡하게 얽혀있음을 의미함
	disentangle 되어야함

