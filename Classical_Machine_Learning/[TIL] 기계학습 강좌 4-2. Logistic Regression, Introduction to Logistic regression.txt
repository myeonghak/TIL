[TIL] 기계학습 강좌 4-2. Logistic Regression, Introduction to Logistic regression



1. Logistic Function
	- sigmoid함수의 특성
	1) bounded(구간이 정해짐)
	2) 미분 가능
	3) 실수 함수
	4) 모든 실수 입력값에 대해 양의 미분값을 가짐 (단조증가?)
	- 하이퍼볼릭탄젠트, 아크탄젠트 등의 activation function을 비롯해 여러 종류의 sigmoid가 존재, 그 중 로지스틱 함수를 사용
	- f(x)=1/(1+e^-x), 0-1사이에 정의됨
	- 인구 증가와 관련이 있음
	- 왜 좋은가?
	1) 시그모이드 함수임
	2) 미분이 쉬움
	- logit function: 로지스틱 함수의 역함수로, f(x)=log(x/(1-x))

2. Logistic Function
	* 1)-> 2)-> 3)-> 4)로 진행
	1) f(x)=log(x/(1-x)) 
	- logit->logistic, X와 y의 역함수
	- 로짓 함수의 x는 확률이 됨
	- P(Y|X)를 근사하기 위해 선형회귀 모델을 적합할 경우, X*theta=P(Y|X)가 됨
	- 그러나 이렇게 하면 확률 axiom을 지키지 못함
	2) x=log(p/(1-p))
	3) ax+b= log(p/(1-p))
	- 더 나은 모델 피팅을 위해 식을 변형, linear shift
	- a는 squeeze하는 정도이고, b는 위치를 조정함
	- 이로써 P(Y|X)를 근사하기 위해 로지스틱 모델을 적합함
	4) X*theta= log(p/(1-p))
	- 선형회귀에서, ax+b를 dummy를 포함한 X와 weight인 theta를 사용해 식을 표현
	- X*theta=log(P(Y|X)/(1-P(Y|X)))

3. Logistic Regression
	- 로지스틱 회귀는 이항분포/다항분포의 라벨을 예측하는 확률적 분류 모델임
	- 로지스틱 함수에 조건부 확률을 적합함으로써 이를 성취
	- 이제 파라미터 theta를 학습하고, inference하는 과정이 중요함