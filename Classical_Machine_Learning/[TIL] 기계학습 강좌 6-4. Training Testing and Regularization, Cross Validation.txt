[TIL] 기계학습 강좌 6-4. Training Testing and Regularization, Cross Validation



1. https://youtu.be/KfobQA4RHZE

2. 

3. 

4. 현실에서는 infinite한 데이터를 사용해 bias and variance를 계산할 수 없음. 이를 모사하기 위해 cross validation이라는 실험을 셋팅하는 것임

5. CV를 하는 이유: average hypothesis를 구하고, 그리고 그 variance와 confidence interval을 구하기 위함. 이를 위해서는 무한한 샘플링이 필요한데, 현실적인 데이터 제약 하에서 N개로 쪼개어 시도하는 것. 이 과정은 bias-variance tradeoff를 분석하여 average hypothesis를 찾아가는 과정에서 유래가 됨.

6. 앞선 예시에서는, bias-variance trade off가 존재. 이걸 측정하기 위해  true function을 generate함. 또, infinite한 수의 데이터포인트 d를 생성해주어야 하는데, 그게 안되므로 한번에 2개씩만 생성하고 hypothesis를 여러번 생성했음.

7. 그러나 현실에서는 true function을 알 수 있는 방법은 없음. 목표 함수에서 관측된 무한한 수의 샘플이 존재하지 않음.

8. 이를 보완하기 위해, 미래에 샘플이 등장했을 때의 반응을 시뮬레이팅 해볼 수 있음. 이를 통해 infinite한 샘플을 통해 hypothesis가 어떻게 변하는지를 보는 과정이 되는 것임.

9. 즉, infinite한 sampling을 n번만 샘플링 해봄으로써 따라할 수 있다는 것. 이를 모사하기 위한 여러 방법 중 k-fold cross validation이 있음.

10. k-fold Cross-validation
	- 주어진 데이터셋을 N개의 상호배제적인 데이터 서브셋으로 만듦. 
	- N-1개의 데이터 서브셋으로 모델을 학습하고, 나머지 1개의 서브셋으로 성능을 측정함.
	- 즉 “우리는 N-1개 까지의 데이터만을 지금까지 관측한 셈이고, 나머지 1개는 미래의 데이터다”라고 가정하는 것임.
	- 이 과정을 infinite하게 해야하는데, 못하니  N번만이라도 해보자는 이야기가 됨.

11. LOOCV(Leave One Out Cross Validation): CV의 극단적인 케이스로, 1개의 샘플을 제외하고 모두 학습에 사용하고 나머지 하나로 예측을 수행하는 방식

12. 실용적인 측면에서는, k개의 모델로 앙상블을 수행하는 것, 혹은 최적의 모델을 선택하는 방식 등으로 활용할 수 있을듯.