[베이지안 개인화 랭킹]

https://medium.com/@radleaf/bpr-and-recommendation-system-3d9a3975c132

1. 저자는 BPR을 최적화 기준 BPR-Opt와 최적화 알고리즘 LearnBPR 2부분으로 나누어 제안.
2. 각 아이템에 대해 정확한 평점을 예측하는 것 보다는, 모든 쌍 (i,j)에 대해 유관 유저 선호도를 예측해야한다.
3. 따라서 모든 쌍(i,j)에 대해 적절한 예측의 수를 극대화해야 함. 이는 AUC를 극대화하는 것과 같음. (ROC 커브 아래의 면적)
4. 그러나 AUC 산식은 미분 불가능한 헤비사이드 계단 함수를 포함하고 있으므로, 그대로 사용할 수 없음.
5. 이를 해결하기 위해 BPR-OPT는 헤비사이드 계단함수를 sigmoid로 대체함. 그 결과 미분이 가능해지고, GD 알고리즘을 사용할 수 있게 됨.
6. 이로써 고객의 선호 확률을 표현하는 산식을 얻을 수 있음.
7. 이제 LearnBPR을 사용해서 BPR-OPT를 극대화하는 파라미터 Θ(theta)를 구함.

8. 또한, 특정 유저에 대한 우도 함수 {p(>u |Θ) : 파라미터 Θ가 주어졌을 때 , 유저 u가 i를 j보다 선호할 가능성.}는 Bayes Theorem으로 정리될 수 있음. 이를 위해서 다음 가정이 필요함.
	1) 모든 유저는 다른 유저와는 독립적으로 행동한다.
	2) 특정 유저에 대한 각 아이템 쌍 (i,j)의 순서는 독립적이다.
	
9. 따라서, 모든 유저의 선호 확률은 파라미터가 주어졌을 때의 상품에 대한 상대 선호 확률의 product로 계산할 수 있다.
10. log함수는 강한 증가 함수이기 때문에, BPR-OPT를 log를 취해 정의한다. 이는 미분가능하며, 따라서 기울기가 계산 가능하다.
11. 전체 데이터를 유저 기준으로 정렬해 학습하면 수렴이 되지 않기 때문에, 저자는 부트스트랩 샘플링을 각 에폭마다 수행할 것을 권장한다.

12. 이제 MF방식에 BPR을 적용하는 법을 설명한다.
MF -> X = WH^T
기존의 MF 방식과는 다르게, LearnBPR에서는 기존에 존재하는 rating matrix를 근사하는 것이 아니라 i를 j보다 높게 평가할지에 대한 문제를 풀고 싶다.

13. 다음 단계를 따른다.
	1) 이미 존재하는 rating matrix를 사용해 Ds 데이터를 만든다(아이템별로 선호 구조를 표현)
	2) X는 W와 H의 행렬곱으로 이루어졌으므로, X의 미분 값을 구할 수 있음.
	이 미분 값을 LearnBPR 알고리즘과 결합함으로써, 매번 pair(u,i,j)를 샘플링해 Θ를 업데이트 할 수 있다.
	