파이토치 10: CNN

	1.	이미지의 경우에 256*256*3의 형식으로 차원이 주어짐. 이를 일정 크기의 필터를 사용해 일정 간격으로 이동하면서 컨볼루션를 수행함. 
	
	2.	가령 2*2 필터가 있을 때 이 필터의 각 블록에 하나의 값이 있음. 
		이 필터를 이동해나가며 이미지 위의 필터와 겹쳐지는 구간의 값을 그에 상응하는 필터의 값으로 곱해준 뒤 하나의 스칼라로 더해줌. 이 과정은 내적으로 계산이 됨. 
		
	3.	이를 W*X=WX^T로 표현, 이는 행렬 내 벡터간의 내적
	
	4.	padding: 이미지 마지막 테두리 부분의 정보를 (피처맵 상에) 표현하기 위해 0으로 채워주는 기법
	
	5.	feature map: 컨볼루션 필터를 적용한 결과로써 얻어지는 이전 레이어 데이터의 국소적인 피처를 표현해내는 행렬(또는 벡터)
		(activation maps과 동일한 개념)
	
	6.	stride: 한번 필터를 적용한 뒤 다음 적용 시에 몇 칸 너머의 데이터에 적용할지를 결정하는 인자.
	
	7.	색상 차원이 있는 이미지의 경우에도 동일하게, 색상의 depth(rgb의 경우 3차원)만큼 컨볼루션 필터를 적용해줌. 
		이 경우, 3차원의 필터를 여러번 적용함에 따라 32*32*10의 결과가 출력될 수도 있음.
		
	8.	max pooling(맥스풀링): 이전 레이어의 값에 컨볼루션 필터를 적용하되, 해당 필터 내의 가장 큰 값을 취해 다음으로 넘겨 줌.
	
	9.	avg pooling: 맥스풀링과 같은 원리로, 필터 내의 값을 평균 취해주너 다음으로 넘김.
	
	10.	fully connected neural net과 차이점: locally connected neural net임.
	
	11.	torch에서는 torch.nn.Conv2d()로 활용.
		torch.nn.Conv2d(입력 차원(1색상이면 1), 출력 차원(아웃풋을 10채널로 내고 싶으면 10), kernel_size=5(5*5 필터를 적용하고 싶다))
		
	12.	maxpooling은 torch.MaxPool2d(kernel_size)로만 입력
	
	13.	마지막의 fully connected layer에는 알맞는 차원 (n,k)를 입력해 주어야 하는데, 이 n의 값이 확실치 않을 경우 일단 실행하면 torch가 이전 레이어의 값을 알려줌. 이에 맞게 보정하면 됨
	
	14.	flatten을 위해서는
		x=x.view(in_size, -1)
		
		<torch.view 예시>
		4*4 텐서를 2*8 텐서로 변환함
		>>> t = torch.rand(4, 4)
		>>> b = t.view(2, 8)
		
		이 때, (input_size, -1)을 입력해주면 flatten해주게 됨.
		