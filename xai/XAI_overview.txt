
[PDP (Partial Dependence Plots)]
: 피처의 수치를 선형적으로 변형하면서 알고리즘의 해석능력이 얼마나 증가하고 감소하는지를 관찰하는 방식

* 해석 방법에 대해 더 공부 필요
	
1. 특징
	1) 시각적 표현의 용이성: 피처의 값이 변할 때 모델에 미치는 영향을 가시적으로 이해할 수 있음.
	2) 쉬운 구현: pdpbox 패키지로 구현되어 있음, 쉽게 활용 가능
	3) 이론적 배경:
		예측 결과와 피처가 어떤 관계에 있든 상관도를 그릴 수 있게 공식을 설계했음.
		부분 의존성 함수는 x_s와 x_c를 입력값으로 받는데, 
		여기서 x_s는 시각화해야할 피처를 의미하고 x_c는 머신러닝 모델이 사용하는, s 집합 원소 이외의 피처들임.
		이 때 x_s는 하나 또는 두개의 피처로 구성된다 (그 이상의 피처를 표현하기 어려움)
		
		몬테카를로 적분법(난수를 무작위로 생성하여 함수의 적분값을 추정하는 방식)으로 부분 의존성 함수를 근사할 수 있음.
		

2. 주의점
	1) 피처간의 독립성 가정: 피처 c와 피처 s의 상관관계가 적다는 가정을 가짐. 만약 상관관계가 높을 경우 피처 c에 지나치게 의존적으로 PDP가 그려질 것임.
	2) 제한된 피처 s 개수: 최대 2개까지의 피처로 S 구성, 그 이상을 시각화하기 어려움
	
	

[대리분석 Surrogate Analysis]
: 본래 기능을 흉내내는 간단한 대체제를 만들어 프로토타입이 동작하는지 판단하는 분석 방법.
인공지능모델이 지나치게 복잡해서 분석이 불가능할 때 유사한 기능을 흉내내는 설명가능한 AI 모델 여러개를 모델로 만들어 본래 모델을 분석하는 기법.

다른 이름: 근사치 모델(Approximation model), 반응 표현기법(RSM, Response Surface Model), 에뮬레이터(Emulator)

핵심 이론: 분석해야할 모델을 f라고 할 대, 대리분석 모델은 f를 흉내내는 g를 만듦. 모델 g는 모델 f의 학습 방식과 같을 수도 있고 다를 수도 있음. (트리-트리계열, 트리-선형회귀)
		g 모델을 선정하는 조건은 (1) f보다 학습 용이 (2) 설명 가능 (3) f 모델 모사 가능
		
		
학습 과정: 
	1) 학습 데이터 전부를 사용해 g를 학습시키는 데 사용
	2) 학습 데이터의 일부만 추려서, 혹은 데이터 라벨별로 추려서 모델 g를 학습
		
대리 분석의 두가지 종류:
	1) 글로벌 대리 분석(Global Surrogate Analysis): 모델 f를 학습시킬 때 사용한 학습데이터 전체 혹은 일부를 사용
	2) 로컬 대리 분석(Local Surrogate Analysis): 데이터 라벨별로, 혹은 학습 데이터의 일부만을 추려서 모델 g 학습 
	
모델 에그노스틱(model-agnostic technology)
: 모델에 대한 지식이 없이도 학습할 수 있는 성질을 의미. 대리분석의 가장 큰 장점이다.
-> 중간에 모델이 바뀌더라도 피처만 같다면 대리분석을 수행할 수 있음. 그 이유는 대리분석 모델과 블랙박스 모델이 완전히 분리되어 있는 성질때문.


[글로벌 대리 분석]
: 전체 학습데이터를 사용해, 블랙박스 함수 f를 모사하는 유사함수 g를 만들고 g를 해석가능하도록 변조하는 방법

분석 절차:
	1) 데이터 집합 X를 선택
	2) X로 f 학습, 블랙박스 모델 f의 예측결과 계산
	3) X로 g 학습, 최대한 f의 결과와 유사하도록 모델 튜닝(ex, R^2의 경우 SSR을 기준으로 비교)-> 모델 g를 XAI 기법을 사용해 해석
장점:
	1) 유연성: 다양한 XAI 기법을 자유롭게 적용 가능
	2) 직관성: 직관적인 설명 가능. 구현이 쉽고 설명이 단순.
단점:
	1) 간접 설명의 한계: f가 아니라 g를 사용해 대리로 설명하기 때문에, 해석 방향에 결함이 있을 수 있음.
	2) 설명 가능성 판단 기준이 주관적: g가 f를 얼마나 유사하게 모방해야지 해석을 잘 할 수 있다 판단할지 애매함.
	3) X의 편향 가능성: 학습데이터 X가 편향되어 있을 경우, XAI의 신뢰도가 떨어짐
	
[로컬 대리 분석 (LIME, Local Interpretable Model-agnostic Explanations)]
: 학습 기법과 관계없이 모델을 설명할 수 있는 로컬 설명가능모델
글로벌 대리분석과는 달리 데이터 하나에 대해 원래 모델이 분류한 결과를 해부함.
대개 이미지와 텍스트 데이터와 같이 매트릭스 형태로 들어오는 데이터 중 중요한 부분을 시각적으로 표현함

가정: 해석 가능 함수인 선형함수만을 사용해도 결정경계를 충분히 표현할 수 있다는 가정을 사용 -> 이미지와 그 근처의 이미지에 대해 탐색하기 때문

원리:
	이미지 분류 문제를 예시로 설명
	1) 이미지 변형(perturbation)/ 샘플 퍼뮤테이션(sample permutation):
		입력 이미지에 대해 해석가능하도록 인식 단위를 쪼개고 이미지를 해석
	2) 슈퍼픽셀 정의:
		이미지 내의 특정 관심 영역을 x라고 하고, 초점 주변으로 x로부터 동일한 정보를 가지고 있다고 간주할 수 있는 영역(즉 x와 유사한 이미지 영역)을
		phi_x라고 부름. 이를 슈퍼픽셀(super pixel)이라고 부른다.
	3) 대리 모델 학습:
		블랙박스 모델을 f라고 하고, 슈퍼픽셀 phi_x의 마스킹 정보를 m_x라고 할 때 이를 입력으로 받아 f(phi_x)와 동일한 값을 뱉어내도록 학습한 XAI 모델을 g라고 정의
		g는 이 슈퍼픽셀 phi_x가 블랙박스 모델 f가 예측하는 데 얼마나 영향을 미치는지 예측함.
		g는 사람이 이해하기 쉬운 모델로 w_1*m_1+w_2*m_2 ... 처럼 선형결합으로 모델 정의. 
		이를 통해 m_1이라는 마스크(phi_1 슈퍼픽셀의 마스크값)값이 얼마나 영향을 미치나 계산 
		손실함수를 설명가능성의 역으로 두어, 최소화 시키는 방식으로 학습 수행
		-> LIME은 슈퍼픽셀 phi_x의 모든 조합에 대한 분류 결과와 g의 결과가 최대한 같게 출력되도록 학습함. 그 결과 모델 f가 가장 영향을 많이 받는 슈퍼픽셀을 찾아냄.
		
	4) 결정 경계의 학습:
		블랙박스 모델 f가 학습한 결정 경계를 학습하기 위해, 입력 이미지를 중심으로 근방 주변 이미지를 샘플링
		슈퍼 픽셀들로 일부만 선택한 이미지를 입력한 f의 출력값과 원래 f 출력을 비교하며 유사한지 아닌지를 비교
		일부 이미지는 긍정적인 예측, 일부는 부정적인 예측을 가할 것 -> 이러한 정보를 바탕으로 g를 학습하여 결정경계를 찾아냄
		
	5) g의 해석:
		학습이 완료되면, g(m_1,m_2,m_3...)=w_1*m_1+w_2*m_2+...+w_x*m_x의 형태로 전개됨.
		w_x는 phi_x의 중요도를 나타내게 됨.
		
장점:
	1) 머신러닝 알고리즘에 관계없이 XAI 적용 가능. (모델 애그노스틱)
	2) 다른 XAI 알고리즘에 비해 매우 가벼움.
	3) 매트릭스로 표현가능한 데이터(텍스트, 이미지)에 대해 작동. 그 결과가 매우 직관적임.

단점:
	1) 비결정적(non-deterministic): 슈퍼 픽셀을 구하는 알고리즘과 모델 g의 결정경계 확정 방법이 비결정적임.
	2) 모델 전체로 확장이 어려움: 데이터 하나에 대해 설명하기 때문에 모델 전체에 대한 일관성을 보전하지 못함. 
		-> 서브모듈러 픽(Submodular pick)알고리즘 제시, 데이터셋 전체에 대해 대표성을 띠는 서브모듈러를 선정하는 알고리즘.
		
		


[SHAP (SHapley Additive exPlanations), 섑]
:피처간 독립성을 근거로 덧셈이 가능하도록 만든 알고리즘, 섀플리값과 피처간 독립성을 핵심 아이디어로 가져감.

섀플리 값(Shapley value): 전체 성과를 창출하는 데 각 참여자가 얼마나 공헌했는지를 수치로 표현.
						각 사람의 기여도는 그 사람의 기여도를 제외했을 때 전체 성과의 변화정도로 표현 가능하다는 설명.
						ex. 주택 가격에서 강과의 거리가 집값에 영향을 끼친다면 강제로 강가에서의 거리를 늘렸을 때 집값의 변동을 예측한 뒤 원래 집값에서 빼어 주면
						그 차이가 강과의 거리가 집 값에 이바지하는 정도라고 추론한다.
						
						
		
		

						
						

		

	
		
		
		
		
		
		
		


